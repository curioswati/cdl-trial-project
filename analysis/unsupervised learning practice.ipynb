{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import normalize, Normalizer, StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram, fcluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wrangler\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '01._Receipt_-_DDOReceipt_Head_Date_and_Challan_Wise.csv'\n",
    "filepath = utils.get_munged_filepath(filename)\n",
    "df = pd.read_csv(filepath, parse_dates=True)\n",
    "df = wrangler.wrangle_data_for_receipt(df, ['RECEIPTHEAD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '10._Expenditure_-_DDO_Head_of_AccountSOE_and_VoucherBillNO_wise.csv'\n",
    "filepath = utils.get_munged_filepath(file)\n",
    "df = pd.read_csv(filepath, parse_dates=True)\n",
    "df = wrangler.wrangle_data_for_consolidated_query(df, ['DDODESC', 'DISTRICT', 'TREASURY', 'DDO'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.groupby('DISTRICT',).sum()\n",
    "samples = data.loc[:, ['AGDED', 'BTDED', 'NETPAYMENT']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding optimal k, select the k using elbow method from the plot\n",
    "ks = np.arange(1, 11)\n",
    "inertias = []\n",
    "for k in ks:\n",
    "    model = KMeans(n_clusters=k)\n",
    "    model.fit(samples)\n",
    "    inertias.append(model.inertia_)\n",
    "plt.scatter(ks, inertias)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-SNE method to plot dataset with multiple dimensions. t-SNE reduces the data to two dimensions.\n",
    "# Import TSNE\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Create a TSNE instance: model\n",
    "model = TSNE(learning_rate=50)\n",
    "\n",
    "# Apply fit_transform to normalized_movements: tsne_features\n",
    "tsne_features = model.fit_transform(normalize(samples))\n",
    "\n",
    "# Select the 0th feature: xs\n",
    "xs = tsne_features[:, 0]\n",
    "\n",
    "# Select the 1th feature: ys\n",
    "ys = tsne_features[:,1]\n",
    "\n",
    "# Scatter plot\n",
    "plt.scatter(xs, ys, alpha=0.5)\n",
    "\n",
    "# Annotate the points\n",
    "for x, y, district in zip(xs, ys, data.index.values):\n",
    "    plt.annotate(district, (x, y), fontsize=5, alpha=0.75)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pipeline to get labels for samples\n",
    "scaler = Normalizer()\n",
    "model = KMeans(n_clusters=2)\n",
    "pipeline = make_pipeline(scaler, model)\n",
    "pipeline.fit(samples)\n",
    "labels = pipeline.predict(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce clusters in hierarchical clustering with fcluster to get crosstab like k-Means clustering.\n",
    "normalized_samples = normalize(samples)\n",
    "mergings = linkage(normalized_samples, method='single')\n",
    "labels = fcluster(mergings, 0.02, criterion='distance')\n",
    "# dendrogram(mergings,\n",
    "#          labels=data.index.values,\n",
    "#          leaf_rotation=90,\n",
    "#          leaf_font_size=6)\n",
    "# plt.show()\n",
    "result = pd.DataFrame({'labels': labels, 'districts': data.index.values}, columns=['labels', 'districts'])\n",
    "ct = pd.crosstab(result['labels'], result['districts'])\n",
    "print(ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hierarchical clustering using linkage and dendrograms\n",
    "normalized_samples = normalize(samples)\n",
    "mergings = linkage(normalized_samples, method='complete')\n",
    "dendrogram(mergings,\n",
    "         labels=data.index.values,\n",
    "         leaf_rotation=90,\n",
    "         leaf_font_size=6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute crosstab for labels and targets\n",
    "result = pd.DataFrame({'labels': labels, 'districts': data.index.values}, columns=['labels', 'districts'])\n",
    "ct = pd.crosstab(result['labels'], result['districts'])\n",
    "print(ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building word frequency matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "documents = df.DDODESC.unique()\n",
    "tfidf = TfidfVectorizer()\n",
    "csr_mat = tfidf.fit_transform(documents).toarray()\n",
    "words = tfidf.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use truncatedsvd to make clusters for word frequency data.\n",
    "# here we use truncatedsvd as a replacement to PCA for sparse matrix data.\n",
    "# It's job is to reduce dimensions as PCA do.\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# Create a TruncatedSVD instance: svd\n",
    "svd = TruncatedSVD(n_components=50)\n",
    "\n",
    "# Create a KMeans instance: kmeans\n",
    "kmeans = KMeans(n_clusters=6)\n",
    "\n",
    "# Create a pipeline: pipeline\n",
    "pipeline = make_pipeline(svd, kmeans)\n",
    "\n",
    "# Fit the pipeline to articles\n",
    "pipeline.fit(csr_mat)\n",
    "\n",
    "# Calculate the cluster labels: labels\n",
    "labels = pipeline.predict(csr_mat)\n",
    "\n",
    "# Create a DataFrame aligning labels and titles: df\n",
    "new_df = pd.DataFrame({'label': labels, 'indices': documents})\n",
    "\n",
    "# Display df sorted by cluster label\n",
    "print(new_df.sort_values(by='label'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.          0.17068064  0.          0.          0.        ]\n",
      " [ 0.          0.06057202  0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.1071551   0.          0.        ]\n",
      " ..., \n",
      " [ 0.          0.11518857  0.          0.          0.          0.        ]\n",
      " [ 0.          0.09016079  0.          0.00180996  0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.16997347]]\n"
     ]
    }
   ],
   "source": [
    "# use NMF for dimension reduction.\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "# Create an NMF instance: model\n",
    "model = NMF(n_components=6)\n",
    "\n",
    "# Fit the model to articles\n",
    "model.fit(csr_mat)\n",
    "\n",
    "# Transform the articles: nmf_features\n",
    "nmf_features = model.transform(csr_mat)\n",
    "\n",
    "# Print the NMF features\n",
    "print(nmf_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRINCIPAL GOVT. DEGREE COLLEGE KHAD        1.000000\n",
      "PRINCIPAL GOVT DEGREE COLLEGE DARLAGHAT    1.000000\n",
      "PRINCIPAL GOVT DEGREE COLLEGE THACHI       0.999998\n",
      "PRINCIPAL GOVT DEGREE COLLEGE DADASIBA     0.999997\n",
      "PRINCIPAL GOVT DEGREE COLLEGE              0.999997\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# recommender system with NMF\n",
    "\n",
    "norm_features = normalize(nmf_features)\n",
    "new_df = pd.DataFrame(norm_features, index=documents)\n",
    "ddo = new_df.loc['PRINCIPAL GOVT. DEGREE COLLEGE KHAD']\n",
    "similar = new_df.dot(ddo)\n",
    "print(similar.nlargest())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
